#!/usr/bin/env python3
"""
AIè‡ªåŠ¨åŒ–åšå®¢ç³»ç»Ÿ v3.0 - é›†æˆå¾®ä¿¡å…¬ä¼—å·å‘å¸ƒ
"""

import asyncio
import os
import sys
import json
from datetime import datetime
from typing import Dict, List, Optional
import argparse

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

from scripts.utils.logger import setup_logger
from scripts.utils.config_loader import load_config
from scripts.collectors.collector_runner import CollectorRunner
from scripts.analyzers.trend_analyzer import TrendAnalyzer
from scripts.generators.article_generator import ArticleGenerator
from scripts.publishers.hugo_publisher import HugoPublisher
from scripts.publishers.wechat_publisher import WeChatPublisher
from scripts.monitoring.system_monitor import SystemMonitor


class AIBlogAutomationV3:
    """AIåšå®¢è‡ªåŠ¨åŒ–ç³»ç»Ÿ v3.0"""
    
    def __init__(self, config_path: str = "config/config.yaml"):
        """åˆå§‹åŒ–ç³»ç»Ÿ"""
        self.config = load_config(config_path)
        self.logger = setup_logger("automation_v3")
        
        # åˆå§‹åŒ–å„æ¨¡å—
        self.collector_runner = CollectorRunner(self.config)
        self.trend_analyzer = TrendAnalyzer(self.config)
        self.article_generator = ArticleGenerator(self.config)
        self.hugo_publisher = HugoPublisher(self.config)
        self.wechat_publisher = WeChatPublisher(config_path)
        self.system_monitor = SystemMonitor(self.config)
        
        # è¿è¡Œç»Ÿè®¡
        self.stats = {
            'start_time': None,
            'end_time': None,
            'articles_collected': 0,
            'articles_analyzed': 0,
            'articles_generated': 0,
            'articles_published': 0,
            'wechat_drafts_created': 0,
            'errors': []
        }
    
    async def run_pipeline(self) -> Dict:
        """è¿è¡Œå®Œæ•´æµæ°´çº¿"""
        self.stats['start_time'] = datetime.now().isoformat()
        self.logger.info("ğŸš€ å¯åŠ¨AIåšå®¢è‡ªåŠ¨åŒ–æµæ°´çº¿ v3.0")
        
        try:
            # 1. ç³»ç»Ÿå¥åº·æ£€æŸ¥
            self.logger.info("ğŸ” æ­¥éª¤1: ç³»ç»Ÿå¥åº·æ£€æŸ¥")
            health_status = await self.system_monitor.check_system_health()
            if not health_status['healthy']:
                self.logger.error(f"ç³»ç»Ÿå¥åº·æ£€æŸ¥å¤±è´¥: {health_status['issues']}")
                return self._generate_error_report("ç³»ç»Ÿå¥åº·æ£€æŸ¥å¤±è´¥")
            
            # 2. æ•°æ®é‡‡é›†
            self.logger.info("ğŸ“¥ æ­¥éª¤2: æ•°æ®é‡‡é›†")
            collected_data = await self.collector_runner.run_all_collectors()
            self.stats['articles_collected'] = len(collected_data)
            self.logger.info(f"é‡‡é›†å®Œæˆ: {self.stats['articles_collected']} æ¡æ•°æ®")
            
            if not collected_data:
                self.logger.warning("æœªé‡‡é›†åˆ°æ•°æ®ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ç»§ç»­")
                collected_data = self._get_sample_data()
            
            # 3. AIè¶‹åŠ¿åˆ†æ
            self.logger.info("ğŸ§  æ­¥éª¤3: AIè¶‹åŠ¿åˆ†æ")
            analysis_results = []
            for industry, articles in collected_data.items():
                if articles:
                    self.logger.info(f"åˆ†æ {industry} è¡Œä¸šæ•°æ®...")
                    analysis = await self.trend_analyzer.analyze_trends(articles, industry)
                    if analysis:
                        analysis_results.append({
                            'industry': industry,
                            'analysis': analysis,
                            'source_count': len(articles)
                        })
                        self.stats['articles_analyzed'] += len(articles)
            
            # 4. å†…å®¹ç”Ÿæˆ
            self.logger.info("ğŸ“ æ­¥éª¤4: å†…å®¹ç”Ÿæˆ")
            generated_articles = []
            for result in analysis_results:
                article = self.article_generator.generate_article(
                    analysis=result['analysis'],
                    industry=result['industry'],
                    source_count=result['source_count']
                )
                if article:
                    generated_articles.append(article)
                    self.stats['articles_generated'] += 1
            
            # 5. å‘å¸ƒåˆ°Hugoåšå®¢
            self.logger.info("ğŸŒ æ­¥éª¤5: å‘å¸ƒåˆ°Hugoåšå®¢")
            published_articles = []
            for article in generated_articles:
                publish_result = self.hugo_publisher.publish_article(article)
                if publish_result['success']:
                    published_articles.append({
                        'file_path': publish_result['file_path'],
                        'metadata': article['metadata']
                    })
                    self.stats['articles_published'] += 1
            
            # 6. å¾®ä¿¡å…¬ä¼—å·å‘å¸ƒï¼ˆå¦‚æœå¯ç”¨ï¼‰
            wechat_results = []
            if self.config.get('publishing', {}).get('wechat', {}).get('enabled', False):
                self.logger.info("ğŸ“± æ­¥éª¤6: å¾®ä¿¡å…¬ä¼—å·å‘å¸ƒ")
                for article_info in published_articles:
                    wechat_result = self.wechat_publisher.publish_to_wechat(
                        article_info['file_path'],
                        article_info['metadata']
                    )
                    wechat_results.append(wechat_result)
                    if wechat_result.get('media_id'):
                        self.stats['wechat_drafts_created'] += 1
            
            # 7. ç”ŸæˆæŠ¥å‘Š
            self.logger.info("ğŸ“Š æ­¥éª¤7: ç”ŸæˆæŠ¥å‘Š")
            report = self._generate_report(
                collected_data=collected_data,
                analysis_results=analysis_results,
                published_articles=published_articles,
                wechat_results=wechat_results
            )
            
            self.stats['end_time'] = datetime.now().isoformat()
            self.logger.info("âœ… AIåšå®¢è‡ªåŠ¨åŒ–æµæ°´çº¿å®Œæˆ")
            
            return report
            
        except Exception as e:
            self.logger.error(f"æµæ°´çº¿æ‰§è¡Œå¤±è´¥: {e}")
            self.stats['errors'].append(str(e))
            return self._generate_error_report(str(e))
    
    def _get_sample_data(self) -> Dict:
        """è·å–ç¤ºä¾‹æ•°æ®ï¼ˆå½“é‡‡é›†å¤±è´¥æ—¶ä½¿ç”¨ï¼‰"""
        return {
            'ç§‘æŠ€': [
                {
                    'title': 'AIèŠ¯ç‰‡æŠ€æœ¯æ–°çªç ´',
                    'content': 'æœ€æ–°ç ”ç©¶æ˜¾ç¤ºï¼Œæ–°ä¸€ä»£AIèŠ¯ç‰‡èƒ½æ•ˆæ¯”æå‡40%',
                    'source': 'æ¨¡æ‹Ÿæ•°æ®',
                    'url': 'https://example.com'
                }
            ],
            'é‡‘è': [
                {
                    'title': 'æ•°å­—äººæ°‘å¸è¯•ç‚¹æ‰©å¤§',
                    'content': 'æ•°å­—äººæ°‘å¸åœ¨æ›´å¤šåŸå¸‚å¼€å±•è¯•ç‚¹åº”ç”¨',
                    'source': 'æ¨¡æ‹Ÿæ•°æ®', 
                    'url': 'https://example.com'
                }
            ]
        }
    
    def _generate_report(self, **kwargs) -> Dict:
        """ç”Ÿæˆæ‰§è¡ŒæŠ¥å‘Š"""
        report = {
            'timestamp': datetime.now().isoformat(),
            'stats': self.stats,
            'success': True,
            'pipeline_version': '3.0',
            'config_used': {
                'wechat_enabled': self.config.get('publishing', {}).get('wechat', {}).get('enabled', False),
                'auto_publish': self.config.get('publishing', {}).get('auto_publish', True)
            }
        }
        
        # æ·»åŠ å„é˜¶æ®µç»“æœ
        for key, value in kwargs.items():
            if isinstance(value, dict) or isinstance(value, list):
                report[key] = value
        
        # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
        report_dir = self.config.get('storage', {}).get('reports_dir', './data/reports')
        os.makedirs(report_dir, exist_ok=True)
        
        report_file = os.path.join(report_dir, f"pipeline_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json")
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        self.logger.info(f"æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        return report
    
    def _generate_error_report(self, error_message: str) -> Dict:
        """ç”Ÿæˆé”™è¯¯æŠ¥å‘Š"""
        self.stats['end_time'] = datetime.now().isoformat()
        
        error_report = {
            'timestamp': datetime.now().isoformat(),
            'stats': self.stats,
            'success': False,
            'error': error_message,
            'pipeline_version': '3.0'
        }
        
        # ä¿å­˜é”™è¯¯æŠ¥å‘Š
        report_dir = self.config.get('storage', {}).get('reports_dir', './data/reports')
        os.makedirs(report_dir, exist_ok=True)
        
        error_file = os.path.join(report_dir, f"error_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json")
        with open(error_file, 'w', encoding='utf-8') as f:
            json.dump(error_report, f, ensure_ascii=False, indent=2)
        
        self.logger.error(f"é”™è¯¯æŠ¥å‘Šå·²ä¿å­˜: {error_file}")
        return error_report


async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='AIåšå®¢è‡ªåŠ¨åŒ–ç³»ç»Ÿ v3.0')
    parser.add_argument('--config', default='config/config.yaml', help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--test', action='store_true', help='æµ‹è¯•æ¨¡å¼')
    args = parser.parse_args()
    
    print("ğŸ¤– AIåšå®¢è‡ªåŠ¨åŒ–ç³»ç»Ÿ v3.0")
    print("=" * 50)
    
    # åˆå§‹åŒ–ç³»ç»Ÿ
    automation = AIBlogAutomationV3(args.config)
    
    if args.test:
        print("ğŸ§ª æµ‹è¯•æ¨¡å¼: ä»…æ£€æŸ¥é…ç½®å’Œä¾èµ–")
        # è¿™é‡Œå¯ä»¥æ·»åŠ æµ‹è¯•é€»è¾‘
        print("âœ… ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
        return
    
    # è¿è¡Œæµæ°´çº¿
    print("ğŸš€ å¼€å§‹æ‰§è¡Œè‡ªåŠ¨åŒ–æµæ°´çº¿...")
    result = await automation.run_pipeline()
    
    # è¾“å‡ºç»“æœæ‘˜è¦
    print("\n" + "=" * 50)
    print("ğŸ“Š æ‰§è¡Œç»“æœæ‘˜è¦")
    print("-" * 30)
    
    if result['success']:
        print(f"âœ… æµæ°´çº¿æ‰§è¡ŒæˆåŠŸ!")
        print(f"   é‡‡é›†æ–‡ç« : {result['stats']['articles_collected']}")
        print(f"   åˆ†ææ–‡ç« : {result['stats']['articles_analyzed']}")
        print(f"   ç”Ÿæˆæ–‡ç« : {result['stats']['articles_generated']}")
        print(f"   å‘å¸ƒæ–‡ç« : {result['stats']['articles_published']}")
        
        if result['config_used']['wechat_enabled']:
            print(f"   å¾®ä¿¡è‰ç¨¿: {result['stats']['wechat_drafts_created']}")
        
        print(f"\nâ±ï¸  å¼€å§‹æ—¶é—´: {result['stats']['start_time']}")
        print(f"   ç»“æŸæ—¶é—´: {result['stats']['end_time']}")
        
        print("\nğŸ¯ ä¸‹ä¸€æ­¥:")
        print("   1. è®¿é—®åšå®¢: https://gsaecy.github.io")
        if result['config_used']['wechat_enabled']:
            print("   2. æ£€æŸ¥å¾®ä¿¡å…¬ä¼—å·è‰ç¨¿ç®±")
        print("   3. æŸ¥çœ‹è¯¦ç»†æŠ¥å‘Š: data/reports/")
        
    else:
        print(f"âŒ æµæ°´çº¿æ‰§è¡Œå¤±è´¥!")
        print(f"   é”™è¯¯: {result['error']}")
        print(f"\nğŸ”§ å»ºè®®:")
        print("   1. æ£€æŸ¥é…ç½®æ–‡ä»¶")
        print("   2. éªŒè¯APIå¯†é’¥")
        print("   3. æŸ¥çœ‹é”™è¯¯æ—¥å¿—")
    
    print("\n" + "=" * 50)


if __name__ == "__main__":
    asyncio.run(main())