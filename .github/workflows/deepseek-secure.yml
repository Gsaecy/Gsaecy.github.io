name: AI Blog with DeepSeek (Secure)

on:
  schedule:
    - cron: '0 2 * * *'  # æ¯å¤©10:00ï¼ˆUTC+8ï¼‰
    - cron: '0 6 * * *'  # æ¯å¤©14:00ï¼ˆUTC+8ï¼‰
  
  workflow_dispatch:
    inputs:
      analysis_type:
        description: 'åˆ†æžç±»åž‹'
        required: true
        default: 'daily'
        type: choice
        options:
          - daily
          - weekly
          - test
  
  push:
    branches: [main]
    paths:
      - '.github/workflows/deepseek-secure.yml'
      - 'scripts/**'
      - 'config/**'

env:
  PYTHON_VERSION: '3.11'
  HUGO_VERSION: 'latest'

# å®‰å…¨æƒé™è®¾ç½® - åªç»™å¿…è¦çš„æƒé™
permissions:
  contents: write  # éœ€è¦å†™å…¥å†…å®¹æ–‡ä»¶
  pages: write     # éœ€è¦éƒ¨ç½²åˆ°GitHub Pages
  id-token: write  # éœ€è¦OIDC token

jobs:
  setup:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          submodules: recursive
          fetch-depth: 0
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          pip install openai beautifulsoup4 requests feedparser schedule
      
      - name: Verify environment
        run: |
          echo "çŽ¯å¢ƒæ£€æŸ¥..."
          echo "Pythonç‰ˆæœ¬: $(python --version)"
          echo "å·¥ä½œç›®å½•: $(pwd)"
          echo "æ–‡ä»¶åˆ—è¡¨:"
          ls -la scripts/ || echo "scriptsç›®å½•ä¸å­˜åœ¨"

  collect:
    needs: setup
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          submodules: recursive
          fetch-depth: 0
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install openai beautifulsoup4 requests feedparser
      
      - name: Run data collection
        env:
          # ä»ŽGitHub Secretså®‰å…¨èŽ·å–API Key
          DEEPSEEK_API_KEY: ${{ secrets.DEEPSEEK_API_KEY }}
        run: |
          echo "å¼€å§‹æ•°æ®é‡‡é›†..."
          mkdir -p logs data/raw
          
          # æµ‹è¯•API Keyæ˜¯å¦å¯ç”¨
          if [ -z "$DEEPSEEK_API_KEY" ]; then
            echo "âŒ é”™è¯¯: DEEPSEEK_API_KEYæœªè®¾ç½®"
            echo "è¯·åœ¨GitHubä»“åº“è®¾ç½®Secrets:"
            echo "1. è®¿é—®ä»“åº“Settings â†’ Secrets and variables â†’ Actions"
            echo "2. ç‚¹å‡»New repository secret"
            echo "3. åç§°: DEEPSEEK_API_KEY"
            echo "4. å€¼: ä½ çš„DeepSeek API Key"
            exit 1
          fi
          
          echo "âœ… API Keyå·²è®¾ç½®ï¼ˆé•¿åº¦: ${#DEEPSEEK_API_KEY}ï¼‰"
          
          # è¿è¡Œé‡‡é›†å™¨
          python scripts/collectors/real_news_collector.py 2>&1 | tee logs/collection.log
          
          echo "é‡‡é›†å®Œæˆï¼ŒæŸ¥çœ‹ç»“æžœ:"
          find data/ -type f 2>/dev/null | head -5 || echo "æ— æ•°æ®æ–‡ä»¶"
      
      - name: Upload collection results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: collection-${{ github.run_id }}
          path: |
            data/
            logs/collection.log
          retention-days: 3

  analyze:
    needs: collect
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          submodules: recursive
          fetch-depth: 0
      
      - name: Download collection results
        uses: actions/download-artifact@v4
        with:
          name: collection-${{ github.run_id }}
          path: ./
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install openai beautifulsoup4 requests feedparser
      
      - name: Run AI analysis with DeepSeek
        env:
          DEEPSEEK_API_KEY: ${{ secrets.DEEPSEEK_API_KEY }}
        run: |
          echo "å¼€å§‹DeepSeek AIåˆ†æž..."
          mkdir -p logs data/analysis
          
          # æ£€æŸ¥æ˜¯å¦æœ‰é‡‡é›†æ•°æ®
          if [ ! -d "data/raw" ] || [ -z "$(ls -A data/raw/ 2>/dev/null)" ]; then
            echo "âš ï¸ æ— é‡‡é›†æ•°æ®ï¼Œä½¿ç”¨ç¤ºä¾‹æ•°æ®..."
            mkdir -p data/raw/$(date +%Y-%m-%d)
            cat > data/raw/$(date +%Y-%m-%d)/sample.json << 'EOF'
            [
              {
                "title": "AIæŠ€æœ¯åŠ é€Ÿè¡Œä¸šå˜é©",
                "content": "äººå·¥æ™ºèƒ½æŠ€æœ¯åœ¨å„è¡Œä¸šåº”ç”¨æ·±åŒ–ï¼ŒæŽ¨åŠ¨æ•°å­—åŒ–è½¬åž‹ã€‚",
                "source": "ç¤ºä¾‹æ•°æ®",
                "industry": "ç§‘æŠ€",
                "importance": "high"
              }
            ]
            EOF
          fi
          
          # è¿è¡ŒDeepSeekåˆ†æžå™¨
          echo "å¯¼å…¥DeepSeekåˆ†æžæ¨¡å—..."
          python -c "
import os, sys, json
from datetime import datetime

# æ·»åŠ è„šæœ¬è·¯å¾„
sys.path.insert(0, 'scripts')

try:
    from analyzers.deepseek_analyzer import DeepSeekAnalyzer
    
    # é…ç½®
    config = {
        'analysis': {
            'ai_model': {
                'provider': 'deepseek',
                'model': 'deepseek-chat',
                'api_base': 'https://api.deepseek.com',
                'api_key': os.getenv('DEEPSEEK_API_KEY'),
                'temperature': 0.7,
                'max_tokens': 2000
            }
        },
        'prompts': {
            'trend_analysis': 'åˆ†æžä»¥ä¸‹è¡Œä¸šæ•°æ®ï¼š{data}',
            'daily_summary': 'ç”Ÿæˆæ¯æ—¥æ‘˜è¦ï¼š{content}',
            'article_generation': 'ç”Ÿæˆåˆ†æžæ–‡ç« ï¼š{analysis}'
        }
    }
    
    # åˆå§‹åŒ–åˆ†æžå™¨
    analyzer = DeepSeekAnalyzer(config)
    
    # åŠ è½½é‡‡é›†æ•°æ®
    import glob
    data_files = glob.glob('data/raw/*/*.json') + glob.glob('data/raw/*.json')
    
    if data_files:
        with open(data_files[0], 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        print(f'åˆ†æž {len(data)} æ¡æ•°æ®...')
        
        # è¿è¡Œåˆ†æž
        result = analyzer.analyze(data)
        
        # ä¿å­˜åˆ†æžç»“æžœ
        result_file = f'data/analysis/analysis_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.json'
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        print(f'âœ… åˆ†æžå®Œæˆï¼Œç»“æžœä¿å­˜åˆ°: {result_file}')
        
        # ç”Ÿæˆæ–‡ç« 
        article = analyzer.generate_article(result, 'daily')
        
        if 'error' not in article:
            # ä¿å­˜æ–‡ç« 
            import os
            os.makedirs('content/posts', exist_ok=True)
            
            article_file = f'content/posts/ai-{datetime.now().strftime(\"%Y%m%d-%H%M\")}.md'
            with open(article_file, 'w', encoding='utf-8') as f:
                f.write('---\\n')
                f.write(f'title: \"{article[\"title\"]}\"\\n')
                f.write(f'date: {datetime.now().isoformat()}\\n')
                f.write('draft: false\\n')
                f.write('tags: [\"AIåˆ†æž\", \"è¡Œä¸šæŠ¥å‘Š\"]\\n')
                f.write('categories: [\"ç»¼åˆ\"]\\n')
                f.write(f'description: \"{article.get(\"description\", \"AIç”Ÿæˆçš„è¡Œä¸šåˆ†æžæŠ¥å‘Š\")}\"\\n')
                f.write('author: \"AIæ™ºæ±‡è§‚å¯Ÿ\"\\n')
                f.write('---\\n\\n')
                f.write(article['content'])
            
            print(f'âœ… æ–‡ç« ç”Ÿæˆå®Œæˆ: {article_file}')
        else:
            print(f'âŒ æ–‡ç« ç”Ÿæˆå¤±è´¥: {article.get(\"error\")}')
            
    else:
        print('âŒ æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶')
        
except Exception as e:
    print(f'âŒ åˆ†æžè¿‡ç¨‹å‡ºé”™: {e}')
    import traceback
    traceback.print_exc()
          " 2>&1 | tee logs/analysis.log
      
      - name: Generate fallback article if needed
        if: failure()
        run: |
          echo "ç”Ÿæˆå¤‡ç”¨æ–‡ç« ..."
          mkdir -p content/posts
          
          cat > content/posts/fallback-$(date +%Y%m%d).md << 'EOF'
          ---
          title: "ç³»ç»Ÿç»´æŠ¤ä¸­ - $(date +'%Yå¹´%mæœˆ%dæ—¥')"
          date: $(date -Iseconds)
          draft: false
          tags: ["ç³»ç»Ÿé€šçŸ¥"]
          categories: ["å…¬å‘Š"]
          description: "AIæ™ºæ±‡è§‚å¯Ÿç³»ç»Ÿæ­£åœ¨å‡çº§ç»´æŠ¤"
          ---
          
          # ç³»ç»Ÿç»´æŠ¤é€šçŸ¥
          
          äº²çˆ±çš„è¯»è€…ï¼Œ
          
          AIæ™ºæ±‡è§‚å¯Ÿç³»ç»Ÿæ­£åœ¨è¿›è¡ŒæŠ€æœ¯å‡çº§å’Œä¼˜åŒ–ï¼Œä»Šæ—¥çš„è‡ªåŠ¨åˆ†æžæŠ¥å‘Šæš‚æ—¶æ— æ³•ç”Ÿæˆã€‚
          
          ## ç³»ç»ŸçŠ¶æ€
          - **çŠ¶æ€**: å‡çº§ç»´æŠ¤ä¸­
          - **é¢„è®¡æ¢å¤**: ä¸‹æ¬¡å®šæ—¶ä»»åŠ¡
          - **å½“å‰ç‰ˆæœ¬**: v2.1
          
          ## æ­£åœ¨è¿›è¡Œçš„æ”¹è¿›
          1. ä¼˜åŒ–æ•°æ®é‡‡é›†ç¨³å®šæ€§
          2. æå‡AIåˆ†æžå‡†ç¡®æ€§
          3. å¢žå¼ºç³»ç»Ÿç›‘æŽ§èƒ½åŠ›
          
          æ„Ÿè°¢æ‚¨çš„ç†è§£ä¸Žæ”¯æŒï¼
          
          ---
          *AIæ™ºæ±‡è§‚å¯Ÿç³»ç»Ÿ*
          *æ›´æ–°æ—¶é—´: $(date)*
          EOF
          
          echo "å¤‡ç”¨æ–‡ç« å·²ç”Ÿæˆ"
      
      - name: Upload analysis results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: analysis-${{ github.run_id }}
          path: |
            data/analysis/
            content/posts/
            logs/analysis.log
          retention-days: 3

  build:
    needs: analyze
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          submodules: recursive
          fetch-depth: 0
      
      - name: Download analysis results
        uses: actions/download-artifact@v4
        with:
          name: analysis-${{ github.run_id }}
          path: ./
      
      - name: Setup Hugo
        uses: peaceiris/actions-hugo@v2
        with:
          hugo-version: ${{ env.HUGO_VERSION }}
          extended: true
      
      - name: Build with Hugo
        run: |
          echo "æž„å»ºHugoç«™ç‚¹..."
          hugo --minify 2>&1 | tee logs/hugo-build.log
          echo "âœ… æž„å»ºå®Œæˆ"
          echo "ç”Ÿæˆæ–‡ä»¶:"
          find public/ -type f -name "*.html" | head -5
      
      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: hugo-build-${{ github.run_id }}
          path: |
            public/
            logs/hugo-build.log
          retention-days: 3

  deploy:
    needs: build
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    steps:
      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: hugo-build-${{ github.run_id }}
          path: ./public
      
      - name: Setup Pages
        uses: actions/configure-pages@v4
      
      - name: Upload artifact
        uses: actions/upload-pages-artifact@v4
        with:
          path: ./public
      
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4

  report:
    needs: deploy
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Generate final report
        run: |
          echo "ðŸŽ‰ AIæ™ºæ±‡è§‚å¯Ÿç³»ç»Ÿè¿è¡ŒæŠ¥å‘Š" > report.md
          echo "==========================" >> report.md
          echo "" >> report.md
          echo "## è¿è¡Œä¿¡æ¯" >> report.md
          echo "- **è¿è¡ŒID**: ${{ github.run_id }}" >> report.md
          echo "- **å·¥ä½œæµ**: ${{ github.workflow }}" >> report.md
          echo "- **è§¦å‘æ—¶é—´**: $(date '+%Y-%m-%d %H:%M:%S')" >> report.md
          echo "- **åšå®¢åœ°å€**: https://gsaecy.github.io" >> report.md
          echo "" >> report.md
          echo "## å„é˜¶æ®µçŠ¶æ€" >> report.md
          echo "| é˜¶æ®µ | çŠ¶æ€ |" >> report.md
          echo "|------|------|" >> report.md
          echo "| çŽ¯å¢ƒå‡†å¤‡ | ${{ needs.setup.result }} |" >> report.md
          echo "| æ•°æ®é‡‡é›† | ${{ needs.collect.result }} |" >> report.md
          echo "| AIåˆ†æž | ${{ needs.analyze.result }} |" >> report.md
          echo "| ç«™ç‚¹æž„å»º | ${{ needs.build.result }} |" >> report.md
          echo "| éƒ¨ç½²å‘å¸ƒ | ${{ needs.deploy.result }} |" >> report.md
          echo "" >> report.md
          echo "## ç³»ç»Ÿä¿¡æ¯" >> report.md
          echo "- **ç‰ˆæœ¬**: AIæ™ºæ±‡è§‚å¯Ÿ v2.1" >> report.md
          echo "- **AIæ¨¡åž‹**: DeepSeek" >> report.md
          echo "- **è‡ªåŠ¨åŒ–**: GitHub Actions" >> report.md
          echo "- **å®‰å…¨çº§åˆ«**: ä½¿ç”¨GitHub Secrets" >> report.md
          echo "" >> report.md
          echo "## ä¸‹æ¬¡è¿è¡Œ" >> report.md
          echo "- **æ¯æ—¥10:00**: è¡Œä¸šæ—¥æŠ¥" >> report.md
          echo "- **æ¯æ—¥14:00**: æ·±åº¦åˆ†æž" >> report.md
          echo "" >> report.md
          echo "---" >> report.md
          echo "*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: $(date)*" >> report.md
          
          cat report.md
      
      - name: Upload final report
        uses: actions/upload-artifact@v4
        with:
          name: final-report-${{ github.run_id }}
          path: report.md
          retention-days: 7